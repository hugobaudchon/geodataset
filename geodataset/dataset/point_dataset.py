class DetectionLabeledRasterCocoDataset(BaseLabeledRasterCocoDataset):
    """
    A dataset class that loads COCO datasets and their associated tiles (images). It will recursively search for COCO
    json files and .tif tiles in the specified root folder and its sub-folders. The COCO json files should follow the
    naming convention defined in the :class:`~geodataset.utils.CocoNameConvention` class. COCO jsons generated by this
    library should automatically follow this convention.

    Can be used for object detection tasks, where the annotations are bounding boxes OR segmentations (in this case
    this class will only use the bounding box of the segmentation).

    It can directly be used with a torch.utils.data.DataLoader.

    Parameters
    ----------
    fold: str
        The dataset fold to load (e.g., 'train', 'valid', 'test'...).
    root_path: str or List[str] or pathlib.Path or List[pathlib.Path]
        The root directory of the dataset.
    transform: albumentations.core.composition.Compose
        A composition of transformations to apply to the tiles and their associated annotations
        (applied in __getitem__).
    """
    def __init__(self,
                 fold: str,
                 root_path: str or List[str] or Path or List[Path],
                 transform: albumentations.core.composition.Compose = None,
                 box_padding_percentage: float = 0.0,
                 force_binary_class=None):
        super().__init__(fold=fold, root_path=root_path, transform=transform)
        self.box_padding_percentage = box_padding_percentage
        self.force_binary_class = force_binary_class

        assert 0 <= self.box_padding_percentage <= 1

    def __getitem__(self, idx: int):
        """
        Retrieves a tile and its annotations by index, applying the transform passed to the constructor of the class,
        if any. It also normalizes the tile data between 0 and 1.

        Parameters
        ----------
        idx: int
            The index of the tile to retrieve

        Returns
        -------
        tuple of (numpy.ndarray, dict)
            The transformed tile (image) data, normalized between 0 and 1, and a dictionary containing the annotations
            and metadata of the tile. The dictionary has the following keys:

            - **boxes** (list of numpy.ndarray): A list of bounding boxes for the annotations.
            - **labels** (numpy.ndarray): An array of category ids for the annotations (same length as 'boxes').
            - **area** (list of float): A list of areas for the bounding boxes annotations (same length as 'boxes').
            - **iscrowd** (numpy.ndarray): An array of zeros (same length as 'boxes'). Currently not implemented.
            - **image_id** (numpy.ndarray): A single-value array containing the index of the tile.
        """
        tile_info = self.tiles[idx]

        with rasterio.open(tile_info['path']) as tile_file:
            tile = tile_file.read([1, 2, 3])  # Reading the first three bands

        labels = tile_info['labels']
        bboxes = []

        for label in labels:
            if 'bbox' in label:
                # Directly use the provided bbox
                bbox_coco = label['bbox']
                bbox = box(*[bbox_coco[0], bbox_coco[1], bbox_coco[0] + bbox_coco[2], bbox_coco[1] + bbox_coco[3]])
            else:
                segmentation = label['segmentation']
                if ('is_rle_format' in label and label['is_rle_format']) or isinstance(segmentation, dict):
                    # RLE format
                    bbox = coco_rle_segmentation_to_bbox(segmentation)
                elif ('is_rle_format' in label and not label['is_rle_format']) or isinstance(segmentation, list):
                    # Polygon (coordinates) format
                    bbox = coco_coordinates_segmentation_to_bbox(segmentation)
                else:
                    raise NotImplementedError("Could not find the segmentation type (RLE vs polygon coordinates).")

            if self.box_padding_percentage:
                minx, miny, maxx, maxy = bbox.bounds
                width = maxx - minx
                height = maxy - miny
                padding_x = width * (self.box_padding_percentage / 100)
                padding_y = height * (self.box_padding_percentage / 100)

                new_minx = max(0, minx - padding_x)
                new_miny = max(0, miny - padding_y)
                new_maxx = min(tile.shape[0], maxx + padding_x)
                new_maxy = min(tile.shape[1], maxy + padding_y)

                bbox = box(new_minx, new_miny, new_maxx, new_maxy)

            bboxes.append(np.array([int(x) for x in bbox.bounds]))

        if self.force_binary_class:
            category_ids = np.array([1 for _ in labels])
        else:
            category_ids = np.array([0 if label['category_id'] is None else label['category_id']
                                     for label in labels])

        if self.transform:
            transformed = self.transform(image=tile.transpose((1, 2, 0)),
                                         bboxes=bboxes,
                                         labels=category_ids)
            transformed_image = transformed['image'].transpose((2, 0, 1))
            transformed_bboxes = transformed['bboxes']
            transformed_category_ids = transformed['labels']
        else:
            transformed_image = tile
            transformed_bboxes = bboxes
            transformed_category_ids = category_ids

        transformed_image = transformed_image / 255  # normalizing
        # getting the areas of the boxes, assume pascal_voc box format
        area = np.array([(bboxe[3] - bboxe[1]) * (bboxe[2] - bboxe[0]) for bboxe in transformed_bboxes])
        # suppose all instances are not crowd
        iscrowd = np.zeros((len(transformed_bboxes),))
        # get tile id
        image_id = np.array([idx])
        # group annotations info
        transformed_bboxes = {'boxes': transformed_bboxes, 'labels': transformed_category_ids,
                              'area': area, 'iscrowd': iscrowd, 'image_id': image_id}

        return transformed_image, transformed_bboxes